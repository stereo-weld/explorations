{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝트: 가위바위보 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 필요한 모듈 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터를 준비하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 데이터 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 구글의 teachable machine 사이트(https://teachablemachine.withgoogle.com/)에 접속한다.  \n",
    "(2) 노트북 전면 카메라를 활용하여 가위, 바위, 보 이미지 각 100장을 만든다.  \n",
    "(3) 나(100x3=300 jpg images)와 13명(13x100x3=3900 jpg images)의 이미지 압축파일을 다운로드 했다.  \n",
    "(4) 압축파일을 unzip으로 해제하고, 각 폴더에서 이미지 파일 이외의 것은 제거하고 , png 이미지의 경우에 jpg 이미지로 확장자를 변경한다.   \n",
    "(5) \"가위\" 이미지를 획득한 모양이 다른 사람의 데이터는 제외한다.  \n",
    "(6) 각 사람별로 scissor, rock, paper 폴더에 있는 동일한 이름의 파일들을 하나의 scissor, rock, paper 폴더에 새로운 이름으로 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 데이터 불러오기 + Resize 하기\n",
    "\n",
    "(5) 숫자 손글씨의 경우 이미지 크기가 28x28 이었기 때문에, 우리의 가위, 바위, 보 이미지도 28x28로 만들어야 합니다. 이를 위해서는 PIL 라이브러리를 사용해볼 거예요. 그러려면 먼저 라이브러리를 불러와야 겠죠?\n",
    "혹시 PIL 라이브러리가 없는 경우 필요한 패키지를 설치해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper_train/scissor\n",
      "가위 이미지 개수: 1300\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_train/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "# glob() 함수는 인자로 받은 패턴과 이름이 일치하는 모든 파일과 디렉터리의 리스트를 반환합니다. \n",
    "images = glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size = (28,28)\n",
    "for img in images:\n",
    "    old_img = Image.open(img)\n",
    "    new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "    \n",
    "\n",
    "print(\"가위 이미지 개수:\", len(os.listdir(image_dir_path)))\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로: /home/aiffel/aiffel/rock_scissor_paper_train/rock\n",
      "바위 이미지 개수: 1300\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\")+\"/aiffel/rock_scissor_paper_train/rock\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path)\n",
    "\n",
    "images = glob.glob(image_dir_path + \"/*.jpg\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size = (28, 28)\n",
    "for img in images:\n",
    "    old_img = Image.open(img)\n",
    "    new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "  \n",
    "print(\"바위 이미지 개수:\", len(os.listdir(image_dir_path)))\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로: /home/aiffel/aiffel/rock_scissor_paper_train/paper\n",
      "보 이미지 개수: 1300\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\")+\"/aiffel/rock_scissor_paper_train/paper\"\n",
    "print(\"이미지 디렉토리 경로:\", image_dir_path)\n",
    "\n",
    "images = glob.glob(image_dir_path + \"/*.jpg\")\n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size = (28, 28)\n",
    "for img in images:\n",
    "    old_img = Image.open(img)\n",
    "    new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    "\n",
    "print(\"보 이미지 개수:\", len(os.listdir(image_dir_path)))\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 0 입니다.\n",
      "x_train shape: (3900, 28, 28, 3)\n",
      "y_train shape: (3900,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, num_imgs):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data = num_imgs   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size = 28\n",
    "    color = 3\n",
    "    \n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs = np.zeros(number_of_data*img_size*img_size*color, dtype=np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    labels = np.zeros(number_of_data, dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path + '/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path + '/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path + '/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "train_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_train\"\n",
    "\n",
    "(x_train, y_train) = load_data(image_dir_path, 1300*3)\n",
    "x_train_norm = x_train/255.0       # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train_norm[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4 train, validation, test 데이터 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train data : 다른 사람들의 데이터 1300 x 3 = 3900 images\n",
    "#### test data : 나의 데이터 100 x 3 = 300 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(x_train, \n",
    "#                                                     y_train, \n",
    "#                                                     valid_size=0.2, \n",
    "#                                                     random_state=7)\n",
    "\n",
    "# print('X_train 개수: ', len(X_train), ', X_valid 개수: ', len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import train_test_split \n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) \n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = 0.6\n",
    "# validate_size = 0.2\n",
    "# train, validate, test = np.split(my_data.sample(frac=1), [int(train_size * len(my_data)), int((validate_size + train_size) * len(my_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 딥러닝 네트워크 (모델) 설계하기\n",
    "자 이제 데이터의 준비가 끝났습니다. 이제 여러분들이 가위바위보를 인식하는 딥러닝 네트워크를 설계해 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                51232     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 70,723\n",
      "Trainable params: 70,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_channel_1 = 32\n",
    "n_channel_2 = 64\n",
    "n_dense = 32\n",
    "n_train_epoch = 10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 딥러닝 네트워크 (모델) 학습시키기\n",
    "잘 설계가 되었다면, 이제 학습을 시켜봅시다. 아마도 여러분들의 데이터는 거의 비슷비슷할 것이기 때문에 accuracy가 꽤 높게 나올 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 1.0589 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.9102 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.7810 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.6700 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.5757 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.4961 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 4ms/step - loss: 0.4290 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.3726 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.3251 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.2851 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f19800dbed0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 방식에 대한 환경설정\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 얼마나 잘 만들었는지 확인하기(테스트)\n",
    "여러분들은 300장의 가위바위보 이미지를 만들어 모두 학습에 사용했습니다. 그러므로 테스트 데이터가 없죠. 옆 친구의 이미지 데이터 300장을 받아오세요. 그리고 그것을 테스트 데이터로 하여 test accuracy를 측정해보세요.\n",
    "\n",
    "우선 테스트용 데이터인 x_test, y_test를 만들어 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "def load_data(img_path, num_imgs):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data = num_imgs   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size = 28\n",
    "    color = 3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_test\"\n",
    "(x_test, y_test) = load_data(image_dir_path, 100*3)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_test_norm[1])\n",
    "print('라벨: ', y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.4703 - accuracy: 0.3333\n",
      "test_loss: 1.4702839851379395 \n",
      "test_accuracy: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 더 좋은 네트워크 만들어보기\n",
    "시험용 데이터(x_test)에 대한 인식률(test accuracy)이 train accuracy보다 많이 낮게 나오지는 않았나요?\n",
    "만약 그렇다면 그 이유는 무엇일까요? MNIST 손글씨 데이터 때처럼 test accuracy가 train accuracy에 근접하도록 개선 방법을 찾아 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이미지를 섞지 않은 경우  \n",
    " -- 10/10 - 0s - loss: 2.0839 - accuracy: 0.3333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1 학습용과 검증용 데이터로 분할 및 셔플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_norm, y_train, test_size=0.2, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.2482 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.2099 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.1542 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.1338 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.1171 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.1031 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 0.0914 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1980186310>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 방식에 대한 환경설정\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 0s - loss: 0.0674 - accuracy: 1.0000\n",
      "valid_loss: 0.06740475445985794 \n",
      "valid_accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_accuracy = model.evaluate(x_valid, y_valid, verbose=2)\n",
    "\n",
    "print(\"valid_loss: {} \".format(valid_loss))\n",
    "print(\"valid_accuracy: {}\".format(valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 16.5034 - accuracy: 0.3367\n",
      "test_loss: 16.50341033935547 \n",
      "test_accuracy: 0.33666667342185974\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.predict() 결과 :  [0.9270442  0.03808842 0.03486738]\n",
      "model이 추론한 가장 가능성이 높은 결과 :  0\n",
      "실제 데이터의 라벨 :  0\n"
     ]
    }
   ],
   "source": [
    "predicted_result = model.predict(x_test_norm)  # model이 추론한 확률값. \n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "idx=0  #1번째 x_test를 살펴보자. \n",
    "print('model.predict() 결과 : ', predicted_result[idx])\n",
    "print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
    "print('실제 데이터의 라벨 : ', y_test[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2 하이퍼파라미터 수정\n",
    "* n_channel_1 = 32 --> 64\n",
    "* n_channel_2 = 64 --> 128\n",
    "* n_dense = 32 --> 32 + 64\n",
    "* n_train_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                102432    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 180,387\n",
      "Trainable params: 180,387\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_channel_1 = 64\n",
    "n_channel_2 = 128\n",
    "n_dense = 32\n",
    "n_train_epoch = 10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(n_dense*2, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 1.0666 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.9448 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.8357 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.7388 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.6533 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.5785 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.5131 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.4561 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 1s 10ms/step - loss: 0.4065 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 1s 9ms/step - loss: 0.3634 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f198b20e990>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 방식에 대한 환경설정\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 0s - loss: 0.3346 - accuracy: 1.0000\n",
      "valid_loss: 0.33457672595977783 \n",
      "valid_accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_accuracy = model.evaluate(x_valid, y_valid, verbose=2)\n",
    "\n",
    "print(\"valid_loss: {} \".format(valid_loss))\n",
    "print(\"valid_accuracy: {}\".format(valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 9.0041 - accuracy: 0.3333\n",
      "test_loss: 9.00406551361084 \n",
      "test_accuracy: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습하며 느낀점\n",
    "* 데이터 전처리의 중요성을 알게 되었다.\n",
    "* 좋은 학습 데이터를 준비하기 위해서는 데이터 전처리 이전에 데이터 획득과정부터 고민해야 될것 같다.\n",
    "* 평가용의 정확도 값이 1로 나온 것은 동영상으로 이미지를 캡쳐하다보니 학습용 데이터에도 평가용 데이터와 동일한 것이 있었기 때문이라 생각된다.\n",
    "* 테스트 데이터의 정확도가 0.3333 으로 나왔다는 것은 모델이 랜덤으로 선택하는 경우와 같기 때문에 학습이 제대로 이루어지지 않았다고 할수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
