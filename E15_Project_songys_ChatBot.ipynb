{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indirect-google",
   "metadata": {},
   "source": [
    "# 15. 프로젝트: 한국어 데이터로 챗봇 만들기\n",
    "\n",
    "영어로 만들었던 챗봇을 한국어 데이터로 바꿔서 훈련시켜봅시다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-timeline",
   "metadata": {},
   "source": [
    "## 루브릭\n",
    "\n",
    "|평가문항|\t상세기준|\n",
    "|:-------|:-------|\n",
    "|1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.|**공백과 특수문자 처리, 토크나이징, 병렬데이터 구축**의 과정이 적절히 진행되었다.|\n",
    "|2. 트랜스포머 모델을 구현하여 **한국어 챗봇 모델 학습을 정상적으로 진행**하였다.|구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.|\n",
    "|3. 한국어 입력문장에 대해 **한국어로 답변하는 함수를 구현**하였다.|한국어 입력문장에 그럴듯한 한국어로 답변을 리턴하였다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-impression",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기\n",
    "\n",
    "한국어 챗봇 데이터는 **송영숙님이 공개한 챗봇 데이터**를 사용합니다.\n",
    "\n",
    "이 데이터는 아래의 링크에서 다운로드할 수 있습니다.\n",
    "\n",
    "[songys/Chatbot_data](https://github.com/songys/Chatbot_data/blob/master/ChatbotData%20.csv)\n",
    "\n",
    "`wget으로 데이터 다운로드`\n",
    "` wget https://github.com/songys/Chatbot_data/raw/master/ChatbotData%20.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-italic",
   "metadata": {},
   "source": [
    "### 패키지 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surface-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 가져오기\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-lottery",
   "metadata": {},
   "source": [
    "### 챗봇의 데이터 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ranging-concentrate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 챗봇의 데이터 받아오기\n",
    "path_to_folder = os.getenv(\"HOME\")+\"/aiffel/songys_chatbot/\"\n",
    "\n",
    "path_to_data = os.path.join(path_to_folder, 'ChatbotData.csv')\n",
    "\n",
    "chatbot = pd.read_csv(path_to_data)\n",
    "chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-basement",
   "metadata": {},
   "source": [
    "### Data description.\n",
    "\n",
    "[인공데이터](https://github.com/songys/Chatbot_data)입니다.  \n",
    "**일부 이별과 관련된 질문**에서 \n",
    "  - 다음카페 \"사랑보다 아름다운 실연( http://cafe116.daum.net/_c21_/home?grpid=1bld )\"에서 \n",
    "  - 자주 나오는 이야기들을 참고하여 제작하였습니다.   \n",
    "  - 가령 \"이별한 지 열흘(또는 100일) 되었어요\"라는 질문에 \n",
    "    - **챗봇이 위로한다는 취지로 답변을 작성**하였습니다.\n",
    "\n",
    "1. 챗봇 트레이닝용 **문답 페어 11,876개**\n",
    "2. 일상다반서 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-association",
   "metadata": {},
   "source": [
    "송영숙님의 데이터 설명서(Data description)에서는 문답 페어가 11,876개라고 했는데 chatbot 데이터의 shape는 (11823, 3)으로 53개의 데이터가 모자란다.  \n",
    "챗봇 데이터가 그 사이에 수정되었을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-eagle",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기\n",
    "\n",
    "영어 데이터와는 전혀 다른 데이터인 만큼 \n",
    "  - 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 \n",
    "  - **전체적으로는 다른 전처리를 수행**해야 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-dragon",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mathematical-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "  \n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"하루가 또 가네요.\" => \"하루가 또 가네요 .\"와 같이\n",
    "    # \"가네요\"와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)   # 4개의 구두점(! ? , .)이 있는 경우에 구두점 앞에 공백을 만듦\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)         # 공백 1개 이상인 경우에 공백 1개로 만듦\n",
    "  \n",
    "    # (ㄱ-힣, a-z, A-Z, 0-9, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^ㄱ-힣a-zA-Z0-9?.!,]+\", \" \", sentence)  \n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-attribute",
   "metadata": {},
   "source": [
    "* 한국어 검출 : \"ㄱ~힣\"\n",
    "* 숫자 검출 : \"0~9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dimensional-theorem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수 (챗봇 트레이닝용 문답 페어 갯수)\n",
    "MAX_SAMPLES = chatbot.shape[0]\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-increase",
   "metadata": {},
   "source": [
    "* 데이터의 갯수가 충분이 크다면 학습시간을 고려하여 최대 갯수를 한정하겠지만 그렇지 않은 경우에는 데이터 전체를 학습에 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "large-marshall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12시 땡!,하루가 또 가네요.,0\n",
      "\n",
      "1지망 학교 떨어졌어,위로해 드립니다.,0\n",
      "\n",
      "3박4일 놀러가고 싶다,여행은 언제나 좋죠.,0\n",
      "\n",
      "3박4일 정도 놀러가고 싶다,여행은 언제나 좋죠.,0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 원본 데이터 5줄 확인\n",
    "def printLines(file, n=5):\n",
    "    with open(file, 'r') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[1:n]:\n",
    "        print(line)\n",
    "#         conversation = line.split(',')\n",
    "#         print(preprocess_sentence(conversation[0]))    # 1번째 컬럼(Q)\n",
    "#         print(preprocess_sentence(conversation[1]))    # 2번째 컬럼(A)\n",
    "#         print(preprocess_sentence(conversation[2]))    # 3번째 컬럼(Label)\n",
    "\n",
    "printLines(path_to_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-matrix",
   "metadata": {},
   "source": [
    "* 하나의 행의 데이터는 콤마(,)로 구분됨\n",
    "* 'rb' 옵션으로 파일을 열면, 하나의 행은 `\\r\\n` 으로 끝남\n",
    "  - `b'12\\xec\\x8b\\x9c \\xeb\\x95\\xa1!,\\xed\\x95\\x98\\xeb\\xa3\\xa8\\xea\\xb0\\x80 \\xeb\\x98\\x90 \\xea\\xb0\\x80\\xeb\\x84\\xa4\\xec\\x9a\\x94.,0\\r\\n'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-arrow",
   "metadata": {},
   "source": [
    "### 데이터 쌍 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "corresponding-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "  \n",
    "    inputs, outputs, labels = [], [], []\n",
    "    \n",
    "    with open(path_to_data, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "  \n",
    "    for line in lines[1:]:\n",
    "        conversation = line.replace('\\r\\n', '').split(',')\n",
    "  \n",
    "        # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
    "        inputs.append(preprocess_sentence(conversation[0]))   # 1번째 컬럼(Q)\n",
    "        outputs.append(preprocess_sentence(conversation[1]))  # 2번째 컬럼(A)\n",
    "        labels.append(preprocess_sentence(conversation[2]))   # 3번째 컬럼(Label)\n",
    "\n",
    "        if len(inputs) >= MAX_SAMPLES:\n",
    "            return inputs, outputs, labels\n",
    "\n",
    "    return inputs, outputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "presidential-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장\n",
    "questions, answers, labels = load_conversations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-electricity",
   "metadata": {},
   "source": [
    "### 어텐션\n",
    "\n",
    "#### 포지셔널 인코딩 레이어\n",
    "단어가 문장의 몇 번째 어순으로 입력되었는지를 모델에 추가로 알려 주기 위해 (위치 정보를 가진 백터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "timely-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어 구하는 클래스\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "  \n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "  \n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "  \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-estonia",
   "metadata": {},
   "source": [
    "* tf.pow()\n",
    "* tf.cast()\n",
    "* tf.range()\n",
    "* tf.math.sin()\n",
    "* tf.math.cos()\n",
    "* tf.concat()\n",
    "* tf.newaxis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-moderator",
   "metadata": {},
   "source": [
    "#### 스케일드 닷 프로덕트 어텐션\n",
    "\n",
    "단어들 간의 유사도를 구하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "religious-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"어텐션 가중치를 계산.\"\"\"\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "  \n",
    "    # scale matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "  \n",
    "    # add the mask to zero out padding tokens\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "  \n",
    "    # softmax is normalized on the last axis (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "  \n",
    "    output = tf.matmul(attention_weights, value)\n",
    "  \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-ordinary",
   "metadata": {},
   "source": [
    "* tf.matmul()\n",
    "* tf.math.sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-clinic",
   "metadata": {},
   "source": [
    "#### 멀티 헤드 어텐션\n",
    "어텐션을 병렬로 수행하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vietnamese-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션을 병렬로 수행하는 멀티 헤드 어텐션 함수\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "    \n",
    "        assert d_model % self.num_heads == 0\n",
    "    \n",
    "        self.depth = d_model // self.num_heads\n",
    "    \n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    \n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "      \n",
    "    \n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(inputs, \n",
    "                            shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  \n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "    \n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "    \n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "    \n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "    \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "    \n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "    \n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "    \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-recipient",
   "metadata": {},
   "source": [
    "* tf.reshape()\n",
    "* tf.transpose()\n",
    "* self.split_heads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-liberal",
   "metadata": {},
   "source": [
    "### 마스킹 \n",
    "\n",
    "#### 패딩 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "regulated-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  패딩 마스킹(Padding Masking)을 구현한 함수\n",
    "def create_padding_mask(x):\n",
    "    # 숫자 0인 위치 체크\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    \n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]    # 숫자가 0인 부분을 체크한 벡터를 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-instrument",
   "metadata": {},
   "source": [
    "#### 룩 어헤드 마스킹\n",
    "자신보다 다음에 나올 단어를 참고하지 않도록 가리는 기법  \n",
    "Query 단어 뒤에 나오는 Key 단어들에 대해서는 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exotic-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 룩 어헤드 마스킹(Look-ahead masking, 다음 단어 가리기)을 구현한 함수\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    \n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-gossip",
   "metadata": {},
   "source": [
    "* tf.linalg.band_part()\n",
    "* tf.ones()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-worship",
   "metadata": {},
   "source": [
    "### 인코더 & 디코더\n",
    "\n",
    "#### 인코더 하나의 레이어\n",
    "2개의 서브 층(sublayer) 으로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "super-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 구현한 함수\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  \n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "  \n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "  \n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "  \n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "  \n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "  \n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-guatemala",
   "metadata": {},
   "source": [
    "* tf.keras.layers.LayerNormalization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-colon",
   "metadata": {},
   "source": [
    "#### 트랜스포머의 인코더\n",
    "임베딩 층(Embedding layer)과 포지셔널 인코딩(Positional Encoding)을 연결하고, 사용자가 원하는 만큼 인코더 층을 쌓아서 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "executive-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머의 인코더 함수\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    # Functional Model 사용 (2개의 input)\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  \n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "  \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  \n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  \n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "  \n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(units=units,\n",
    "                                d_model=d_model,\n",
    "                                num_heads=num_heads,\n",
    "                                dropout=dropout,\n",
    "                                name=\"encoder_layer_{}\".format(i),\n",
    "                                )([outputs, padding_mask])\n",
    "  \n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], \n",
    "                          outputs=outputs, \n",
    "                          name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-communications",
   "metadata": {},
   "source": [
    "#### 디코더 하나의 레이어\n",
    " 세 개의 서브 층(sublayer)으로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "expired-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 구현한 함수\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), \n",
    "                            name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), \n",
    "                                 name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), \n",
    "                                     name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), \n",
    "                                  name='padding_mask')\n",
    "  \n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(d_model, \n",
    "                                    num_heads, \n",
    "                                    name=\"attention_1\")(inputs={'query': inputs,\n",
    "                                                                'key': inputs,\n",
    "                                                                'value': inputs,\n",
    "                                                                'mask': look_ahead_mask\n",
    "                                                                })\n",
    "  \n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "  \n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(d_model, \n",
    "                                    num_heads, \n",
    "                                    name=\"attention_2\")(inputs={'query': attention1,\n",
    "                                                                'key': enc_outputs,\n",
    "                                                                'value': enc_outputs,\n",
    "                                                                'mask': padding_mask\n",
    "                                                                })\n",
    "  \n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
    "  \n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "  \n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
    "  \n",
    "    return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "                          outputs=outputs,\n",
    "                          name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-samuel",
   "metadata": {},
   "source": [
    "* tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-monitoring",
   "metadata": {},
   "source": [
    "#### 트랜스포머의 디코더\n",
    "임베딩 층(Embedding layer)과 포지셔널 인코딩(Positional Encoding)을 연결하고, 사용자가 원하는 만큼 디코더 층을 쌓아서 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "familiar-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머의 디코더 함수\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "  \n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "    \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  \n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  \n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "  \n",
    "    # num_layers만큼 쌓아올린 디코더의 층\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(units=units,\n",
    "                                d_model=d_model,\n",
    "                                num_heads=num_heads,\n",
    "                                dropout=dropout,\n",
    "                                name='decoder_layer_{}'.format(i),\n",
    "                                )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "  \n",
    "    return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "                          outputs=outputs,\n",
    "                          name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-store",
   "metadata": {},
   "source": [
    "## Step 3. SubwordTextEncoder 사용하기\n",
    "\n",
    "한국어 데이터는 **형태소 분석기를 사용하여 토크나이징을 해야 한다**고 많은 분이 알고 있습니다.   \n",
    "하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 **내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용**해보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-merit",
   "metadata": {},
   "source": [
    "### 병렬 데이터 전처리하기\n",
    "\n",
    "#### 1. 단어장(Vocabulary) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "extreme-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.2.0 이하)\n",
    "# tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "# (주의) Tensorflow 2.3.0 이상의 버전에서는 아래 주석의 코드를 대신 실행해 주세요. \n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "immediate-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "entire-domestic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8147]\n",
      "END_TOKEN의 번호 : [8148]\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 부여된 정수를 출력해봅시다.\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-calgary",
   "metadata": {},
   "source": [
    "각각 8,147과 8,148라는 점에서 현재 단어장의 크기가 8,147(0번부터 8,146번)이라는 의미입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "joint-sentence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8149\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-synthesis",
   "metadata": {},
   "source": [
    "#### 2. 챗봇 데이터 길이 분포\n",
    "* [참고: 6)패딩 부분](https://wikidocs.net/44249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "colonial-obligation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문의 최대 길이 : 57\n",
      "질문의 평균 길이 : 13.190645352279455\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# questions 데이터의 길이 분포\n",
    "print('질문의 최대 길이 :',max(len(q) for q in questions))\n",
    "print('질문의 평균 길이 :',sum(map(len, questions))/len(questions))\n",
    "\n",
    "plt.hist([len(s) for s in questions], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "inside-martial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변의 최대 길이 : 72\n",
      "답변의 평균 길이 : 15.933434830415292\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# answers 데이터의 길이 분포\n",
    "print('답변의 최대 길이 :',max(len(a) for a in answers))\n",
    "print('답변의 평균 길이 :',sum(map(len, answers))/len(answers))\n",
    "\n",
    "plt.hist([len(s) for s in answers], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-windsor",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "premier-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 샘플 중 길이가 max_len 이하인 샘플의 비율이 몇 %인지 확인하는 함수\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "          if(len(s) <= max_len):\n",
    "                cnt = cnt + 1\n",
    "    name = nested_list      \n",
    "    print(f'전체 샘플 중 길이가 {max_len} 이하인 샘플의 비율: {(cnt / len(nested_list))*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "swedish-monitor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 30 이하인 샘플의 비율: 98.24917533620908\n",
      "전체 샘플 중 길이가 30 이하인 샘플의 비율: 96.37993741013278\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 30\n",
    "\n",
    "below_threshold_len(MAX_LENGTH, questions)\n",
    "below_threshold_len(MAX_LENGTH, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-advocate",
   "metadata": {},
   "source": [
    "샘플 최대 길이를 30으로 하였을 경우 질문의 문장은 98% 이상이 포함된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-mozambique",
   "metadata": {},
   "source": [
    "#### 3. 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "useful-shannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 33번째 질문 샘플: [7851, 1148, 1051, 2]\n",
      "정수 인코딩 후의 33번째 답변 샘플: [1080, 3158, 641, 263, 877, 618, 284, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 33번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 33번째 질문 샘플: {}'.format(tokenizer.encode(questions[32])))\n",
    "print('정수 인코딩 후의 33번째 답변 샘플: {}'.format(tokenizer.encode(answers[32])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "interim-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "    \n",
    "        # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "      \n",
    "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_inputs, \n",
    "                                                                     maxlen=MAX_LENGTH, \n",
    "                                                                     padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_outputs, \n",
    "                                                                      maxlen=MAX_LENGTH, \n",
    "                                                                      padding='post')\n",
    "    \n",
    "    return tokenized_inputs, tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "suspected-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8149\n",
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "# 필터링 후에 단어장의 크기와 샘플의 갯수 확인\n",
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "                                         \n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-chance",
   "metadata": {},
   "source": [
    "필터링 전과 후의 샘플 개수가 11823으로 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-audience",
   "metadata": {},
   "source": [
    "#### 4. 교사 강요(Teacher Forcing) 사용하기\n",
    "\n",
    "모델이 t 시점에서 예측한 값을 t+1 시점에 입력으로 사용하지 않고,   \n",
    "t 시점의 레이블. 즉, 실제 알고있는 정답을 t+1 시점의 입력으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "limiting-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-damage",
   "metadata": {},
   "source": [
    "## Step 4. 모델 구성하기\n",
    "\n",
    "위 실습 내용을 참고하여 트랜스포머 모델을 구현합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "inner-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머 함수\n",
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "  \n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(create_padding_mask, \n",
    "                                              output_shape=(1, 1, None),\n",
    "                                              name='enc_padding_mask')(inputs)\n",
    "  \n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(create_look_ahead_mask,\n",
    "                                             output_shape=(1, None, None),\n",
    "                                             name='look_ahead_mask')(dec_inputs)\n",
    "  \n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(create_padding_mask, \n",
    "                                              output_shape=(1, 1, None),\n",
    "                                              name='dec_padding_mask')(inputs)\n",
    "  \n",
    "    # 인코더\n",
    "    enc_outputs = encoder(vocab_size=vocab_size,\n",
    "                          num_layers=num_layers,\n",
    "                          units=units,\n",
    "                          d_model=d_model,\n",
    "                          num_heads=num_heads,\n",
    "                          dropout=dropout,\n",
    "                          )(inputs=[inputs, enc_padding_mask])\n",
    "  \n",
    "    # 디코더\n",
    "    dec_outputs = decoder(vocab_size=vocab_size,\n",
    "                          num_layers=num_layers,\n",
    "                          units=units,\n",
    "                          d_model=d_model,\n",
    "                          num_heads=num_heads,\n",
    "                          dropout=dropout,\n",
    "                          )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "  \n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "  \n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-store",
   "metadata": {},
   "source": [
    "#### 1. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "extensive-timer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 (None, None, 256)    3140352     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, None, 256)    3667712     dec_inputs[0][0]                 \n",
      "                                                                 encoder[1][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8149)   2094293     decoder[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,902,357\n",
      "Trainable params: 8,902,357\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2  # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256   # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8   # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512     # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1   # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(vocab_size=VOCAB_SIZE,\n",
    "                    num_layers=NUM_LAYERS,\n",
    "                    units=UNITS,\n",
    "                    d_model=D_MODEL,\n",
    "                    num_heads=NUM_HEADS,\n",
    "                    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-legislature",
   "metadata": {},
   "source": [
    "\"Connected to\" 컬럼은 처음 보는데...어떻게 해석해야하나...?   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-prototype",
   "metadata": {},
   "source": [
    "#### 2. 손실 함수(Loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "beneficial-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
    "                                                         reduction='none')(y_true, y_pred)\n",
    "  \n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "  \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-society",
   "metadata": {},
   "source": [
    "#### 3. 커스텀된 학습률(Learning rate)\n",
    "\n",
    "$$\\mathbf{{\\color{Red} {lrate = d_{model}^{-0.5} \\cdot  min \\left (step\\_num^{-0.5}, ~~ step\\_num \\cdot  warmup\\_steps^{-1.5}   \\right )}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "concerned-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 학습률 스케줄링(Custom Learning rate Scheduling) \n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "    \n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "    \n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)             # rsqrt: reciprocal of square root\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "    \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-defeat",
   "metadata": {},
   "source": [
    "#### 4. 모델 컴파일\n",
    "손실 함수와 커스텀 된 학습률(learning rate)을 사용하여 모델을 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "regulation-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, \n",
    "                                     beta_1=0.9, \n",
    "                                     beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    \n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss=loss_function, \n",
    "              metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-athletics",
   "metadata": {},
   "source": [
    "#### 5. 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "interstate-partnership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 1.9313 - accuracy: 0.0328\n",
      "Epoch 2/20\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 1.5680 - accuracy: 0.0662\n",
      "Epoch 3/20\n",
      "185/185 [==============================] - 10s 56ms/step - loss: 1.3435 - accuracy: 0.0677\n",
      "Epoch 4/20\n",
      "185/185 [==============================] - 11s 61ms/step - loss: 1.2438 - accuracy: 0.0725\n",
      "Epoch 5/20\n",
      "185/185 [==============================] - 11s 59ms/step - loss: 1.1671 - accuracy: 0.0768\n",
      "Epoch 6/20\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 1.0877 - accuracy: 0.0823\n",
      "Epoch 7/20\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.9994 - accuracy: 0.0904\n",
      "Epoch 8/20\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.9029 - accuracy: 0.1008\n",
      "Epoch 9/20\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.7979 - accuracy: 0.1124\n",
      "Epoch 10/20\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.6897 - accuracy: 0.1242\n",
      "Epoch 11/20\n",
      "185/185 [==============================] - 10s 57ms/step - loss: 0.5792 - accuracy: 0.1381\n",
      "Epoch 12/20\n",
      "185/185 [==============================] - 11s 58ms/step - loss: 0.4714 - accuracy: 0.1526\n",
      "Epoch 13/20\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.3703 - accuracy: 0.1675\n",
      "Epoch 14/20\n",
      "185/185 [==============================] - 11s 58ms/step - loss: 0.2820 - accuracy: 0.1810\n",
      "Epoch 15/20\n",
      "185/185 [==============================] - 11s 58ms/step - loss: 0.2079 - accuracy: 0.1934\n",
      "Epoch 16/20\n",
      "185/185 [==============================] - 11s 58ms/step - loss: 0.1513 - accuracy: 0.2039\n",
      "Epoch 17/20\n",
      "185/185 [==============================] - 10s 56ms/step - loss: 0.1089 - accuracy: 0.2118\n",
      "Epoch 18/20\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0832 - accuracy: 0.2165\n",
      "Epoch 19/20\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0690 - accuracy: 0.2190\n",
      "Epoch 20/20\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0614 - accuracy: 0.2199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa381a70390>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20   # 20 --> 100\n",
    "\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-machinery",
   "metadata": {},
   "source": [
    "## Step 5. 모델 평가하기\n",
    "\n",
    "Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만듭니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "solid-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 예측(inference) 함수\n",
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "  \n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "  \n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "  \n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "    \n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "    \n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "    \n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "balanced-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇의 대답을 얻는 함수\n",
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "  \n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "  \n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "  \n",
    "    return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "behavioral-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나이 차이가 좀 있는데 고민입니다.\n",
      "출력 : 나이 차이는 극복할 수 있어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'나이 차이는 극복할 수 있어요 .'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 문장으로부터 챗봇의 대답\n",
    "\n",
    "sentence_generation('나이 차이가 좀 있는데 고민입니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-fitting",
   "metadata": {},
   "source": [
    "입력 : 나이 차이가 좀 있는데 고민입니다.  \n",
    "출력20 : 나이 차이는 극복할 수 있어요 .  \n",
    "출력100 : 나이 차이는 중요하지 않아요 .  \n",
    "출력20 : 나이 차이는 극복할 수 있어요 .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "stretch-queen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 자주 만나기 힘드네요!\n",
      "출력 : 덜 힘들었으면 좋겠어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'덜 힘들었으면 좋겠어요 .'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 문장으로부터 챗봇의 대답\n",
    "\n",
    "sentence_generation(\"자주 만나기 힘드네요!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-hunter",
   "metadata": {},
   "source": [
    "입력 : 자주 만나기 힘드네요`!`  \n",
    "출력20 : 성격이 안 맞나봐요 .  \n",
    "출력100 : 좋은 추억만 간직하세요 .  \n",
    "출력20 : 덜 힘들었으면 좋겠어요 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "internal-conspiracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 늦은 밤에 보자고 하는데...\n",
      "출력 : 그냥 얼굴 보면 설레요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그냥 얼굴 보면 설레요 .'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 문장으로부터 챗봇의 대답\n",
    "\n",
    "sentence_generation(\"늦은 밤에 보자고 하는데...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-newark",
   "metadata": {},
   "source": [
    "입력 : 늦은 밤에 보자고 하는데...  \n",
    "출력20 : 당신의 사랑이 생길 거예요 .  \n",
    "출력100 : 너무 신경 곤두세우지 마세요 .  \n",
    "출력20 : 그냥 얼굴 보면 설레요 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "duplicate-secondary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 친구와 같이 술을 먹자고 하네\n",
      "출력 : 연락 확실하게 끊으세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'연락 확실하게 끊으세요 .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 문장으로부터 챗봇의 대답\n",
    "\n",
    "sentence_generation(\"친구와 같이 술을 먹자고 하네\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-poison",
   "metadata": {},
   "source": [
    "입력 : 친구와 같이 술을 먹자고 하네  \n",
    "출력20 : 함께 충분한 대화를 하고 상담을 받아보는 게 좋겠어요 .  \n",
    "출력100 : 한 번 말해보는게 좋겠어요 .  \n",
    "출력20 : 연락 확실하게 끊으세요 .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "sporting-invalid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너무 피곤하다\n",
      "출력 : 자신의 인생을 사세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'자신의 인생을 사세요 .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 문장으로부터 챗봇의 대답\n",
    "\n",
    "sentence_generation(\"너무 피곤하다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-polyester",
   "metadata": {},
   "source": [
    "입력 : 너무 피곤하다  \n",
    "출력20 : 너무 자책하지 마세요 .  \n",
    "출력100 : 마음이 따뜻할 것 같아요 .  \n",
    "출력20 : 자신의 인생을 사세요 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-friendship",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "* 챗봇의 대답을 듣고 훌륭한 대화상대가 생긴 것 같은 기분이 들었다.\n",
    "* 에폭을 증가시켜 훈련한 경우에 동일한 질문에 대해서 다른 대답이 나왔다. 그런데 좀 어색하다.\n",
    "* \"Connected to\" 컬럼은 처음 보는데...어떻게 해석해야하나...?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-optics",
   "metadata": {},
   "source": [
    "## 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-grain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
